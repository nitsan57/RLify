{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# RLify Use a custom NN model example\n",
                "In this file we will see examples of running differnet agent-algorithms, getting the train metric, and watching the agents in actions.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from rlify.models.base_model import BaseModel\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "from torchvision import transforms\n",
                "\n",
                "class my_resnet(BaseModel):\n",
                "    def __init__(self, input_shape, out_shape):\n",
                "        super(my_resnet, self).__init__(input_shape, out_shape)\n",
                "        self.preprocess = transforms.Compose(\n",
                "            [\n",
                "                transforms.Resize(224, antialias=True),\n",
                "            ]\n",
                "        )\n",
                "        self.resnet = torch.hub.load(\n",
                "            \"pytorch/vision:v0.10.0\", \"resnet18\", weights=None\n",
                "        )\n",
                "        self.out_layer = nn.Linear(1000, np.prod(self.out_shape))\n",
                "\n",
                "    def forward(self, x):\n",
                "        # since we know the input is an observation_space=Box(0, 255, (210, 160, 3), np.uint8) and not dict we can just pass x with default key 'data'\n",
                "        # (for  more infor check ObsWrapper class)\n",
                "        x = x[\"data\"]\n",
                "        # we need to permute the input to be in the shape of (batch_size, channels, height, width)\n",
                "        x = self.preprocess(x.permute(0, 3, 1, 2))\n",
                "        x = self.resnet(x)\n",
                "        return self.out_layer(x)\n",
                "\n",
                "    def reset(self):\n",
                "        # we can pass since its not a rnn model\n",
                "        pass"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 1 - Train using discrete PPO\n",
                "lets train a LunaLander gym env"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import gymnasium as gym\n",
                "from rlify.agents.ppo_agent import PPO_Agent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
                        "[Powered by Stella]\n"
                    ]
                }
            ],
            "source": [
                "def norm_obs(x):\n",
                "    return (x / 255).astype(np.float32)\n",
                "\n",
                "env_name = \"Pong-v4\"\n",
                "env = gym.make(env_name, render_mode=None)\n",
                "from gym.wrappers import TransformObservation\n",
                "\n",
                "env = TransformObservation(env, norm_obs)\n",
                "models_shapes = PPO_Agent.get_models_input_output_shape(\n",
                "env.observation_space, env.action_space\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Using cache found in /home/nitsan57/.cache/torch/hub/pytorch_vision_v0.10.0\n",
                        "Using cache found in /home/nitsan57/.cache/torch/hub/pytorch_vision_v0.10.0\n",
                        "episode 0, curr_mean_R:-00019.0, best_mean_R:-19.0, total_steps:1497: : 1497it [01:46, 14.10it/s]             \n"
                    ]
                }
            ],
            "source": [
                "from rlify.utils import init_torch\n",
                "device = init_torch()\n",
                "policy_input_shape = models_shapes[\"policy_nn\"][\"input_shape\"]\n",
                "policy_out_shape = models_shapes[\"policy_nn\"][\"out_shape\"]\n",
                "critic_input_shape = models_shapes[\"critic_nn\"][\"input_shape\"]\n",
                "critic_out_shape = models_shapes[\"critic_nn\"][\"out_shape\"]\n",
                "policy_nn = my_resnet(input_shape=policy_input_shape, out_shape=policy_out_shape)\n",
                "critic_nn = my_resnet(input_shape=critic_input_shape, out_shape=critic_out_shape)\n",
                "\n",
                "agent = PPO_Agent(\n",
                "obs_space=env.observation_space,\n",
                "action_space=env.action_space,\n",
                "device=device,\n",
                "batch_size=64,\n",
                "max_mem_size=10**4,\n",
                "num_parallel_envs=1,\n",
                "lr=3e-4,\n",
                "entropy_coeff=0.05,\n",
                "policy_nn=policy_nn,\n",
                "critic_nn=critic_nn,\n",
                "discount_factor=0.99,\n",
                "kl_div_thresh=0.05,\n",
                "clip_param=0.2,\n",
                "tensorboard_dir=\"./tensorboard/\",\n",
                ")\n",
                "train_stats = agent.train_n_steps(env=env, n_steps=1000)"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "6939f772228930f094315145e416d5954b20b1f6473e0de1ef78293fcab749f1"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 64-bit ('venv': venv)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
